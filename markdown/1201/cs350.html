---
title: CS 350 (archived) - Operating Systems
layout: markdown
---

<div class="content">

<h1>CS 350 (archived) - Operating Systems</h1>

<div class="md-toc content">
    <p class="md-toc-content">
    <span class="md-toc-item md-toc-h1">
        <a class="md-toc-inner" href="#intro">Intro</a>
    </span>
    <span class="md-toc-item md-toc-h1">
        <a class="md-toc-inner" href="#threads">Threads</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#review-from-whatever-course">Review from whatever course</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#concurrent-program-execution">Concurrent Program Execution</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#context-switch">Context Switch</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#thread-states">Thread States</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#preemptive-scheduling">Preemptive Scheduling</a>
    </span>
    <span class="md-toc-item md-toc-h1">
        <a class="md-toc-inner" href="#synchronization">Synchronization</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#spinlocks-in-os/161">Spinlocks in OS/161</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#os/161-locks">OS/161 Locks</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#spinlocks-and-locks:-similarities-and-difference">Spinlocks and Locks: Similarities and Difference</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#wait-channels">Wait Channels</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#semaphore">Semaphore</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#semaphore-implementation">Semaphore Implementation</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#condition-variables">Condition Variables</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#other-sources-of-race-conditions">Other sources of Race conditions</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#deadlocks">Deadlocks</a>
    </span>
    <span class="md-toc-item md-toc-h1">
        <a class="md-toc-inner" href="#process">Process</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#fork">fork</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#_exit">_exit</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#waitpid">waitpid</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#execv">execv</a>
    </span>
    <span class="md-toc-item md-toc-h1">
        <a class="md-toc-inner" href="#system-calls">System Calls</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#kernel-privilege">Kernel Privilege</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#user-and-kernel-stacks">User and Kernel Stacks</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#exception-handling">Exception Handling</a>
    </span>
    <span class="md-toc-item md-toc-h3">
        <a class="md-toc-inner" href="#mips_trap">mips_trap</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#multiprocessing">Multiprocessing</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#stack-diagrams">Stack Diagrams</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#inter-process-communication-(ipc)">Inter-Process Communication (IPC)</a>
    </span>
    <span class="md-toc-item md-toc-h1">
        <a class="md-toc-inner" href="#virtual-memory">Virtual Memory</a>
    </span>
    <span class="md-toc-item md-toc-h2">
        <a class="md-toc-inner" href="#virtual-memory-&amp;-address-translation">Virtual Memory &amp; Address Translation</a>
    </span>
    <span class="md-toc-item md-toc-h3">
        <a class="md-toc-inner" href="#1.-dynamic-relocation">1. Dynamic Relocation</a>
    </span>
    <span class="md-toc-item md-toc-h3">
        <a class="md-toc-inner" href="#2.-segmentation">2. Segmentation</a>
    </span>
    <span class="md-toc-item md-toc-h3">
        <a class="md-toc-inner" href="#3.-paging:-physical-memory">3. Paging: Physical Memory</a>
    </span>
    <span class="md-toc-item md-toc-h3">
        <a class="md-toc-inner" href="#4.-two-level-paging">4. Two-Level Paging</a>
    </span>
    <span class="md-toc-item md-toc-h3">
        <a class="md-toc-inner" href="#5.-multi-level-paging">5. Multi-Level Paging</a>
    </span>
    <span class="md-toc-item md-toc-h1">
        <a class="md-toc-inner" href="#some-good-problems-for-midterm??">Some good problems for midterm??</a>
    </span>
    <span class="md-toc-item md-toc-h1">
        <a class="md-toc-inner" href="#after-midterm">after midterm</a>
    </span>
    </p>
</div>


<!--start--><div class="alert">
  <span class="closebtn" onclick="this.parentElement.style.display='none';">&times;</span>
  If you reach this page by accident, you should know that this page is outdated by the title above...
  This is the old layout with toc (table of contents) at the top which is hard to navigate if I have a lot of contents in one section. Please refer to <a href="/md/1201/cs350">my new layout</a>
  (with contents up to date) with bootstrap toc.
</div>

<p>miscellaneous notes... Also, check my <a href="../cs350help/">help page</a></p>
<p>Lesley&#39;s lectures recording starts from lec 7.</p>
<h1 id="intro"><a class="header-link" href="#intro"></a>Intro</h1>
<p>OS:</p>
<ul class="list">
<li>manages resource</li>
<li>creates execution environments.</li>
</ul>
<p>Three views:</p>
<ol class="list">
<li>Application view: provide services<ul class="list">
<li>part cop: provides protection from program errors. part facilitator: abstract interface to underlying system</li>
<li>What services?<ul class="list">
<li>resources</li>
<li>interfaces</li>
<li>isolates running programs</li>
</ul>
</li>
</ul>
</li>
<li>System view: solve problems<ul class="list">
<li>manages the hardware resources</li>
<li>allocates resources</li>
<li>controls the access to or sharing of resources among programs.</li>
</ul>
</li>
<li>Implementation view: how is it built?<ul class="list">
<li><strong>concurrent</strong>: multi progs or seqs of instrs <em>running, or appearing to run, at the same time</em>.</li>
<li><strong>real-time</strong>: must respond to an event in a specific amount of time.</li>
</ul>
</li>
</ol>
<p><strong>kernel</strong>: The operating system kernel is the part of the operating system that responds to system calls, interrupts and exceptions.</p>
<p><strong>operation system</strong>: The operating system as a whole includes the kernel, and may include other related programs that provide servicesfor applications.  This may include things like:</p>
<ul class="list">
<li>utility programs (e.g. disk defragmenter, task manager)</li>
<li>command interpreters (e.g. cmd.exe in Windows, bash in Linux)</li>
<li>programming libraries (e.g. POSIX threads in Linux)</li>
</ul>
<p><strong>monolithic kernel</strong>: the entire operating system (which includes the device drivers, file system, and the application IPC) is working in kernel space. &quot;everything and the kitchen sink&quot; is a part of the
kernel. This includes device drivers, file system, virtual memory, etc.</p>
<p><strong>microkernel</strong>: only absolutely necessary components are a part of the
kernel. All other elements are user programs.</p>
<p><strong>real-time OS</strong>: an OS with stringent event response times,
guarantees, and preemptive scheduling.</p>
<p>The <strong>execution environment</strong> provided by the OS includes a variety of
<strong>abstract entities</strong> that can be manipulated by a running program.</p>
<h1 id="threads"><a class="header-link" href="#threads"></a>Threads</h1>
<p>seq of instructions.</p>
<p>a single program can have</p>
<ul class="list">
<li>diff threads responsible for different roles</li>
<li>multi threads --- same roles</li>
</ul>
<p>Reasons we use threads:</p>
<ul class="list">
<li>Efficient Use of Resource</li>
<li>parallelism</li>
<li>responsiveness</li>
<li>priority</li>
<li>modularization</li>
</ul>
<p>A thread <strong>blocks</strong>, when it ceases execution for a period of time, or, until some condition has been met (e.g.  a website respondsor a user moves the mouse). CPU is idle.</p>
<p>Key ideas:</p>
<ul class="list">
<li>A thread can create new threads using <code>thread_fork</code></li>
<li>new threads start execution in a function specified as a param to <code>thread_fork</code></li>
<li>original (called <code>thread_fork</code>) and new thread proceed concurrently</li>
<li>All threads share access to program&#39;s global vars and heap</li>
<li>each thread has its own stack (private to that thread)</li>
</ul>
<p>In the OS, a thread is represented as a struct or object</p>
<p>An example of using <code>thread_fork</code> to create a new thread that is running the function <code>vehicle_sumulation</code>.</p>
<pre class="hljs"><code><span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; NumThreads; i++) {
    error = thread_fork(<span class="hljs-string">"vehicle simulation thread"</span>, <span class="hljs-literal">NULL</span>,
        vehicle_simulation, <span class="hljs-literal">NULL</span>, i);
    <span class="hljs-keyword">if</span> (error) {
        panic(<span class="hljs-string">"traffic sim: thread_fork failed: %s"</span>,
            strerror(error));
    }
}</code></pre><p><strong>Interface</strong></p>
<ul class="list">
<li>create a new thread:<pre class="hljs"><code><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">thread_fork</span><span class="hljs-params">(
  <span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span> *name, <span class="hljs-comment">// name of new thread</span>
  <span class="hljs-keyword">struct</span> proc *proc, <span class="hljs-comment">// thread’s process</span>
  <span class="hljs-keyword">void</span> (*func)</span> <span class="hljs-comment">// new thread’s function</span>
      <span class="hljs-params">(<span class="hljs-keyword">void</span> *, <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">long</span>)</span>,
  <span class="hljs-keyword">void</span> *data1, <span class="hljs-comment">// function’s first param</span>
  <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">long</span> data2 <span class="hljs-comment">// function’s second param</span>
)</span>;</code></pre></li>
<li>terminate the calling thread: <code>void thread_exit(void);</code></li>
<li>volutarily yield execution: <code>void thread_yield(void);</code></li>
</ul>
<div class='ex'>
<div class="ex-title">
In-Class Problems: forkprint
</div>

<div class='ex-content'>
<pre>
<code>
main() {
    helper(NULL,0);
}

void
helper(void *p, unsigned long i) { /* parameter p is not used */
    if (i &lt; 3) {
        kprintf(&quot;%ld&quot;,i);           /* print the value of i */
        thread_fork(&quot;helper1&quot;,NULL,helper,NULL,i+1); /* fork thread to run helper(NULL,i+1) */
        thread_fork(&quot;helper2&quot;,NULL,helper,NULL,i+1); /* fork thread to run helper(NULL,i+1) */
    }
    if (i==0) {
        kprintf(&quot;%ld&quot;,i);
    }
    thread_exit();
}
</code>
</pre>
<p>Which of the following outputs could possibly be generated by this program?</p>
<ol type="a">
    <li> 01221220</li>
    <li> 01120222</li>
    <li> 01342560</li>
    <li> 01222120</li>
    <li> 01122220</li>
    <li> 01234560</li>
    <li> 01212220</li>
    <li> 00112222</li>
</ol>
<p><strong>answer</strong>: cdf not possible</p>
<p>Explanation (credit to Nathan Lo on Piazza): We can eliminate c and f as we only print \(i\) when \(i &lt; 3\), so we should never print anything \(&gt;= 3\). </p>

</p>d is trickier: it&#39;s impossible because we observe we print before we fork, so it&#39;s impossible to have a single 1, followed by 3 2&#39;s, as this implies we had one thread with \(i=1\) fork into 3 threads with \(i=2\). Notice that each thread with \(i=1\) spawns exactly 2 threads, so this is impossible.</p>

<p>
The others are correct: the way to see this which was discussed in class was to draw out the &quot;call tree&quot; (fork tree?) of threads and note exactly when the print statement is with respect to the forks.</p>
</div>
</div>

<h2 id="review-from-whatever-course"><a class="header-link" href="#review-from-whatever-course"></a>Review from whatever course</h2>
<p><strong>Review: Sequential Program Execution</strong></p>
<ul class="list">
<li>fetch instr (from code segment) that the Program counter points to</li>
<li>decode and execute the instr and</li>
<li>increment the PC</li>
</ul>
<blockquote>
<p>Note: In CS241 we names the MIPS registers $0, $1,
$2, etc. In CS350 we referred to them by their default function,
e.g. v0, a0, t0.</p>
</blockquote>
<p><code>t0-t7</code>: temps (caller-save). if the calling subroutine has a value in one of
these registers that it wants preserved, it should store the value
on the stack before calling any subroutines and restore it
afterwards.</p>
<p><code>s0-s7</code>: saved (callee-save). if the called subroutine uses one of these
registers is must first store its current value on the stack and
restore it before exiting</p>
<p>This strategy tries to <em>miminize situations where the callee is saving values that the caller is not using</em>.</p>
<p><strong>Review: The Stack</strong>: grows downward in slides.</p>
<p>Conceptually, each thread executes sequentially using its private register contents and stack.</p>
<h2 id="concurrent-program-execution"><a class="header-link" href="#concurrent-program-execution"></a>Concurrent Program Execution</h2>
<p><strong>Key Question</strong>: What is shared between threads?</p>
<ul class="list">
<li>They are both executing (perhaps at the same time on different cores) the same program.</li>
<li>Both threads share the same code, read-only data, global variables and heap.</li>
<li>Each thread has its own stack and PC.</li>
</ul>
<p>Three options:  </p>
<ul class="list">
<li>Hardware support (P processors, C cores, M multithreading per core)</li>
<li>Timesharing: Multiple threads tak turns on the same hardware; rapidly switching.</li>
<li>Hardware support + Timesharing</li>
</ul>
<p>When <strong>timesharing</strong>, the switch from one thread to another is called a <strong>context switch</strong>.</p>
<h2 id="context-switch"><a class="header-link" href="#context-switch"></a>Context Switch</h2>
<ul class="list">
<li>decide which thread will run next (scheduling)</li>
<li>save register contents of current thread</li>
<li>load register contents of next thread</li>
</ul>
<p>Thread context (register values) must be saved/restored
carefully, since thread execution continuously changes the
context.</p>
<p>The threads share the CPU, giving the user the illusion of multiple
programs running at the same time.</p>
<p><strong>On MIPS</strong></p>
<pre class="hljs"><code><span class="hljs-keyword">switchframe_switch:
</span>    <span class="hljs-comment">/* a0: address of switchframe pointer of old thread. */</span>
    <span class="hljs-comment">/* a1: address of switchframe pointer of new thread. */</span>

    <span class="hljs-comment">/* Allocate stack space for saving 10 registers. 10*4 = 40 */</span>
    <span class="hljs-keyword">addi </span><span class="hljs-built_in">sp</span>, <span class="hljs-built_in">sp</span>, -<span class="hljs-number">40</span>
    <span class="hljs-keyword">sw </span><span class="hljs-built_in">ra</span>, <span class="hljs-number">36</span>(<span class="hljs-built_in">sp</span>)   <span class="hljs-comment">/* Save the registers */</span>
    <span class="hljs-keyword">sw </span><span class="hljs-built_in">gp</span>, <span class="hljs-number">32</span>(<span class="hljs-built_in">sp</span>)
    <span class="hljs-keyword">sw </span><span class="hljs-built_in">s8</span>, <span class="hljs-number">28</span>(<span class="hljs-built_in">sp</span>)   <span class="hljs-comment">/* a.k.a. frame pointer */</span>
    <span class="hljs-keyword">sw </span><span class="hljs-built_in">s6</span>, <span class="hljs-number">24</span>(<span class="hljs-built_in">sp</span>)
    <span class="hljs-keyword">sw </span><span class="hljs-built_in">s5</span>, <span class="hljs-number">20</span>(<span class="hljs-built_in">sp</span>)
    <span class="hljs-keyword">sw </span><span class="hljs-built_in">s4</span>, <span class="hljs-number">16</span>(<span class="hljs-built_in">sp</span>)
    <span class="hljs-keyword">sw </span><span class="hljs-built_in">s3</span>, <span class="hljs-number">12</span>(<span class="hljs-built_in">sp</span>)
    <span class="hljs-keyword">sw </span><span class="hljs-built_in">s2</span>, <span class="hljs-number">8</span>(<span class="hljs-built_in">sp</span>)
    <span class="hljs-keyword">sw </span><span class="hljs-built_in">s1</span>, <span class="hljs-number">4</span>(<span class="hljs-built_in">sp</span>)
    <span class="hljs-keyword">sw </span><span class="hljs-built_in">s0</span>, <span class="hljs-number">0</span>(<span class="hljs-built_in">sp</span>)

    <span class="hljs-comment">/* Store the old stack pointer in the old thread */</span>
    <span class="hljs-keyword">sw </span><span class="hljs-built_in">sp</span>, <span class="hljs-number">0</span>(<span class="hljs-built_in">a0</span>)

    <span class="hljs-comment">/* Get the new stack pointer from the new thread */</span>
    <span class="hljs-keyword">lw </span><span class="hljs-built_in">sp</span>, <span class="hljs-number">0</span>(<span class="hljs-built_in">a1</span>)
    <span class="hljs-keyword">nop </span>            <span class="hljs-comment">/* delay slot for load */</span>

    <span class="hljs-comment">/* Now, restore the registers */</span>
    <span class="hljs-keyword">lw </span><span class="hljs-built_in">s0</span>, <span class="hljs-number">0</span>(<span class="hljs-built_in">sp</span>)
    <span class="hljs-keyword">lw </span><span class="hljs-built_in">s1</span>, <span class="hljs-number">4</span>(<span class="hljs-built_in">sp</span>)
    <span class="hljs-keyword">lw </span><span class="hljs-built_in">s2</span>, <span class="hljs-number">8</span>(<span class="hljs-built_in">sp</span>)
    <span class="hljs-keyword">lw </span><span class="hljs-built_in">s3</span>, <span class="hljs-number">12</span>(<span class="hljs-built_in">sp</span>)
    <span class="hljs-keyword">lw </span><span class="hljs-built_in">s4</span>, <span class="hljs-number">16</span>(<span class="hljs-built_in">sp</span>)
    <span class="hljs-keyword">lw </span><span class="hljs-built_in">s5</span>, <span class="hljs-number">20</span>(<span class="hljs-built_in">sp</span>)
    <span class="hljs-keyword">lw </span><span class="hljs-built_in">s6</span>, <span class="hljs-number">24</span>(<span class="hljs-built_in">sp</span>)
    <span class="hljs-keyword">lw </span><span class="hljs-built_in">s8</span>, <span class="hljs-number">28</span>(<span class="hljs-built_in">sp</span>)   <span class="hljs-comment">/* a.k.a. frame pointer */</span>
    <span class="hljs-keyword">lw </span><span class="hljs-built_in">gp</span>, <span class="hljs-number">32</span>(<span class="hljs-built_in">sp</span>)
    <span class="hljs-keyword">lw </span><span class="hljs-built_in">ra</span>, <span class="hljs-number">36</span>(<span class="hljs-built_in">sp</span>)
    <span class="hljs-keyword">nop </span>            <span class="hljs-comment">/* delay slot for load */</span>

    <span class="hljs-comment">/* and return. */</span>
    <span class="hljs-keyword">j </span><span class="hljs-built_in">ra</span>
    <span class="hljs-keyword">addi </span><span class="hljs-built_in">sp</span>, <span class="hljs-built_in">sp</span>, <span class="hljs-number">40</span> <span class="hljs-comment">/* in delay slot */</span>
    <span class="hljs-meta">.end</span> <span class="hljs-keyword">switchframe_switch</span></code></pre><p>C function <code>thread_switch</code> calls the assembly language subroutine <code>switchframe_switch</code>.</p>
<p><code>thread_switch</code> caller: save/restore the <em>caller-save</em> regs, including return address (ra)</p>
<p><code>switchframe_switch</code> callee: save/restore <em>callee-save</em> regs. In OS/161 the frame pointer is callee saved.</p>
<p><code>switchframe_switch</code>, saves callee-save registers to the old
thread’s stack; it restores the callee-save registers from the new
thread’s stack.</p>
<p>MIPS R3000 is pipelined; delay-slots are used to protect against <em>load-use hazards</em>, <em>control hazards</em>.</p>
<p><em>What Causes Context Switches?</em></p>
<ol class="list">
<li><code>thread_yield</code>: voluntarily allows other threads to run</li>
<li><code>thread_exit</code>: terminated</li>
<li>blocks, via a call to <code>wchan_sleep</code>: it is waiting for some resource (such as network access) or for some event to happen</li>
<li>is preempted: it involuntarily stops running (because the thread scheduler stopped it)</li>
</ol>
<h2 id="thread-states"><a class="header-link" href="#thread-states"></a>Thread States</h2>
<p class="img-container"><img src="/pics/thread_state.png" width=100%></p>
<p>Running: current executing. Ready: ready to execute. Blocked: waiting for sth, so not ready to execute.</p>
<p><code>thread_yield</code> (C function) yield CPU. <code>thread_yield</code> calls (C function) <code>thread_switch</code> (high level context switch). <code>thread_switch</code> chooses a new thread then calls (assembly subroutine) <code>switchframe_switch</code> (low level).</p>
<p><strong>Scheduling quantum</strong> imposes a limit on processor time: upper bound on how long a thread can run before it must yield the CPU.</p>
<p>An <strong>interrupt</strong> is an event that occurs during the execution of a program.</p>
<ul class="list">
<li>caused by system devices (hardware): timer, disk controller, network interface card.</li>
<li>when interrupt occurs,  the hardware automatically transfers control to a fixed location in memory (specified by the designer of the CPU).</li>
<li>At that location, the the thread library must place a procedure called an <strong>interrupt handler</strong>.</li>
<li>the interrupt handler normally:<ul class="list">
<li>creates a trap frame to record the thread context at the time of the interrupt,</li>
<li>determines which device caused the interrupt and performs device-specific processing,</li>
<li>restores the saved thread context from the trap frame and resumes execution of the thread.</li>
</ul>
</li>
</ul>
<p><strong>Thread context</strong> is all the information (i.e. register values) needed to resume executing a thread after it has been suspended.
and it&#39;s stored in a switchframe.</p>
<p>When a thread is interrupted all the register values are stored in a <strong>trap frame</strong>.</p>
<h2 id="preemptive-scheduling"><a class="header-link" href="#preemptive-scheduling"></a>Preemptive Scheduling</h2>
<ul class="list">
<li>Threads may block or yield before their quantum has expired.</li>
<li>If a thread has run too long, the timer interrupt handler preempts the thread by calling <code>thread_yield</code>.</li>
<li>The preempted thread changes state from running to ready, and it is placed on the <strong>ready queue</strong>.</li>
<li>OS161 threads use preemptive round-robin scheduling:<ul class="list">
<li>scheduler maintains a queue of threads, often called the ready queue.</li>
<li>On a context switch, the running thread is moved to the end of the ready queue, and the first thread on the queue is allowed to run.</li>
<li>Newly created threads are placed at the end of the ready queue.</li>
</ul>
</li>
<li>Threads can be migrated to other processors or interrupted by device so the order they run is nondeterministic.</li>
</ul>
<p>Then see two examples in slides (one and two threads): involuntary/voluntary context switch.</p>
<div class='ex'>
<div class="ex-title">
Review Questions
</div>

<div class='ex-content'>
<p>Every thread has its own stack.</p>
<p>Threads can only run in parallel (execute instructions simultaneously) if there is hardware support (via multiple CPUs, cores, etc.).</p>
<p>Which of the following are NOT reasons to use threads?</p>
<ul class="list">
    <li>resource utilization</li>
    <li><em>isolation from errors</em></li>
    <li>computation time</li>
    <li>organization</li>
</ul>
</div>
</div>



<div class='ex'>
    <div class="ex-title">In-Class Problems: twothreads</div>
    <div class='ex-content'>
    Suppose that there are two threads in a system that uses preemptive round-robin scheduling with a
    scheduling quantum of Q milliseconds. The system has a single processor. Each thread runs a function
    which behaves as follows

<pre>
<code>
for i from 1 to N do
    compute for C milliseconds
    sleep for S milliseconds
end
</code>
</pre>

    At the end of its for loop, a thread is finished and it exits. During the “compute” part of each iteration,
    a thread is runnable (running or ready to run). During the “sleep” part of each of its iterations, a thread is
    blocked. For both parts of this question assume that C &lt; Q and C &lt; S.
<br><br>
    <strong>a.</strong> First, assume that C &lt; S and C &lt; Q. Suppose that both of the threads are created at time t = 0. At what time will both of the threads be finished? Answer in terms of Q, N, C, and S, as necessary.
<br><br>
    <strong>Soln</strong>: Let <code>C -&gt; XXX, S -&gt; YYYY.</code>

<pre>
<code>
T_0     XXX | YYYYXXX | ... |
T_1         | XXXYYYY | ... | YYYY
</code>
</pre>

    Thus the answer is \(N(C+S)+C\)
<br><br>
    <strong>b.</strong> Answer the same question, but this time assume that S &lt; C &lt; Q.
<br><br>
    <strong>Soln</strong>: Let <code>C -&gt; XXXX, S -&gt; YYYY.</code>

<pre>
<code>
T_0     XXXX | YYYZXXXX | ... | ... YYYZ |
T_1          | XXXXYYYZ | ... | ... XXXX | YYY
</code>
</pre>

    Thus the answer is \(2NC + S\)
    </div>
</div>




<h1 id="synchronization"><a class="header-link" href="#synchronization"></a>Synchronization</h1>
<p>Concurrent threads interact with each other in a variety of ways:</p>
<ul class="list">
<li>All threads in a concurrent program <strong>share access</strong> to the program’s global variables and the heap.</li>
<li>Threads share access, through the operating system, to system devices, such as the hard drive, the display, etc.</li>
</ul>
<p>A common synchronization problem is to enforce <strong>mutual exclusion</strong>.</p>
<p>The part of a concurrent program in which a shared object is accessed (e.g. the intersection) is called a <strong>critical section</strong>.</p>
<p>This coordination of access to a shared resource is called <strong>synchronization</strong>.</p>
<p><em>What happens if several threads try to access the same global variable or heap object at the same time?</em></p>
<p>We require that concurrent programs will run correctly regardless of which order the threads are executed.</p>
<p>A <strong>race condition</strong> is when the program result depends on the order of execution.</p>
<p>To find the critical sections...</p>
<ul class="list">
<li>Inspect each variable and ask is it possible for multiple threads to read and write it concurrently?</li>
<li>Constants and memory that all threads only read do not cause race conditions.</li>
</ul>
<p>The course text defines a critical section as</p>
<blockquote>
<p>A critical section is a piece of code that accesses a shared
variable (or more generally, a shared resource) and must not be
concurrently executed by more than one thread.</p>
</blockquote>
<pre class="hljs"><code>Acquire(<span class="hljs-keyword">bool</span> *lock) {
<span class="hljs-keyword">while</span> (*lock == <span class="hljs-literal">true</span>) {}; <span class="hljs-comment">// spin until lock is free</span>
    *lock = <span class="hljs-literal">true</span>;       <span class="hljs-comment">// grab the lock</span>
}

Release(book *lock) {
    *lock = <span class="hljs-literal">false</span>;      <span class="hljs-comment">// give up the lock</span>
}</code></pre><p>This approach fails because between the time a thread breaks out of
the while loop (i.e. <code>*lock = false</code>) and sets <code>*lock</code> to <code>true</code> it could
be preempted and another thread could come along and set <code>*lock</code> to
<code>true</code>.</p>
<p>We want to create a function so that between when we test <code>*lock</code> and
we set it we do not want another thread to change its value.</p>
<p>We will call this approach <strong>test-and-set</strong> and we will look at three
approaches to implementing it.</p>
<ol class="list">
<li>x86-64’s <code>xchg</code>. Atomic</li>
</ol>
<pre class="hljs"><code>Acquire(<span class="hljs-keyword">bool</span> *lock) {
    <span class="hljs-keyword">while</span> (xchg(lock,<span class="hljs-literal">true</span>) == <span class="hljs-literal">true</span>) {}; <span class="hljs-comment">// test and set</span>
}

Release(<span class="hljs-keyword">bool</span> *lock) {
    *lock = <span class="hljs-literal">false</span>;                      <span class="hljs-comment">// give up lock</span>
}</code></pre><p>This construct is known as a <strong>spinlock</strong>, since a thread busy-waits (loops or spins) in <code>Acquire</code> until the lock is free.</p>
<ol start="2">
<li>ARM’s <code>LDREX</code> and <code>STREX</code></li>
<li>MIPS’s <code>ll</code> and <code>sc</code></li>
</ol>
<p>More on MIPS Synchronization Instructions</p>
<ul class="list">
<li><code>ll</code> (load linked): load value at address addr.</li>
<li><code>sc</code> (store conditional): store new value at addr if the value at addr has not changed since the instruction <code>ll</code> was executed.</li>
<li><code>sc</code> returns SUCCESS if the value stored at the address has not changed since <code>ll</code> was executed.</li>
<li><code>sc</code> does not check what that value at the address is. It only checks if it has changed.</li>
</ul>
<pre class="hljs"><code>MIPSTestAndSet(addr, new_val) {
    old val = ll addr           <span class="hljs-comment">// test</span>
    status = sc addr, new_val   <span class="hljs-comment">// set</span>
    <span class="hljs-keyword">if</span> ( status == SUCCEED ) <span class="hljs-keyword">return</span> old_val
    <span class="hljs-keyword">else</span> <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>            <span class="hljs-comment">// lock is being held</span>
}

Acquire(<span class="hljs-keyword">bool</span> *lock) {           <span class="hljs-comment">// spin until hold lock</span>
    <span class="hljs-keyword">while</span>( MIPSTestAndSet(lock, <span class="hljs-literal">true</span>) == <span class="hljs-literal">true</span> ) {};
}</code></pre><table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:center">lock value at <code>ll</code></th>
<th style="text-align:center">lock value before <code>sc</code></th>
<th style="text-align:center">lock value after <code>sc</code></th>
<th style="text-align:center">status</th>
<th style="text-align:left">Lock State</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">1.</td>
<td style="text-align:center">false</td>
<td style="text-align:center">false</td>
<td style="text-align:center">true</td>
<td style="text-align:center">succeed</td>
<td style="text-align:left"><strong>lock acquired</strong></td>
</tr>
<tr>
<td style="text-align:left">2.</td>
<td style="text-align:center">true</td>
<td style="text-align:center">true</td>
<td style="text-align:center">true</td>
<td style="text-align:center">succeed</td>
<td style="text-align:left"><strong>keep spinning, no lock</strong></td>
</tr>
<tr>
<td style="text-align:left">3.</td>
<td style="text-align:center">false</td>
<td style="text-align:center">true</td>
<td style="text-align:center">true</td>
<td style="text-align:center">fail</td>
<td style="text-align:left"><strong>keep spinning, no lock</strong></td>
</tr>
<tr>
<td style="text-align:left">4.</td>
<td style="text-align:center">true</td>
<td style="text-align:center">false</td>
<td style="text-align:center">false</td>
<td style="text-align:center">fail</td>
<td style="text-align:left"><strong>keep spinning, no lock</strong></td>
</tr>
</tbody>
</table>
<h2 id="spinlocks-in-os/161"><a class="header-link" href="#spinlocks-in-os/161"></a>Spinlocks in OS/161</h2>
<p>A <strong>spinlock</strong> is a lock that spins, i.e. it repeatedly tests the lock’s availability in a loop until the lock is obtained.</p>
<p>When threads uses a spinlock they <strong>busy-wait</strong> i.e. it uses the CPU while they wait for the lock.</p>
<pre class="hljs"><code><span class="hljs-keyword">struct</span> spinlock {
    <span class="hljs-keyword">volatile</span> <span class="hljs-keyword">spinlock_data_t</span> lk_lock;
    <span class="hljs-keyword">struct</span> cpu *lk_holder;
};

<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">spinlock_init</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> spinlock *lk)</span></span>;
<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">spinlock_acquire</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> spinlock *lk)</span></span>;
<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">spinlock_release</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> spinlock *lk)</span></span>;</code></pre><p><code>spinlock_acquire</code> calls <code>spinlock_data_testandset</code> in a loop until the lock is acquired.</p>
<p>OS/161 uses <code>ll</code> and <code>sc</code> to implement test-and-set.</p>
<h2 id="os/161-locks"><a class="header-link" href="#os/161-locks"></a>OS/161 Locks</h2>
<p>In addition to spinlocks, OS/161 also has <strong>locks</strong>.</p>
<p>Like spinlocks, locks are used to enforce mutual exclusion, i.e. they
are a type of mutex.</p>
<pre class="hljs"><code><span class="hljs-keyword">struct</span> lock *mylock = lock_create(<span class="hljs-string">"LockName"</span>);

lock_acquire(mylock);
    <span class="hljs-comment">// critical section</span>
lock_release(mylock);</code></pre><p>Spinlocks spin whereas locks block:</p>
<ul class="list">
<li><code>spinlock_acquire</code> spins until the lock can be acq</li>
<li><code>lock_acquire</code> blcoks until the lock can be acq</li>
</ul>
<p>Locks can be used to protect larger critical sections without being a burden on the CPU.</p>
<h2 id="spinlocks-and-locks:-similarities-and-difference"><a class="header-link" href="#spinlocks-and-locks:-similarities-and-difference"></a>Spinlocks and Locks: Similarities and Difference</h2>
<p>For both you would</p>
<ul class="list">
<li>acquire it, access the critical section, then</li>
<li>release it when you have finished accessing the critical section.</li>
</ul>
<p>Both have owners and can only be released by their owner.</p>
<ul class="list">
<li>A spinlock is owned by a CPU.</li>
<li>A lock is owned by a thread.</li>
</ul>
<p>In OS/161, and most modern OSs, interrupts are disabled on the CPU that holds the spinlock. Preemption is disabled on that CPU (hence, owned by that CPU) but not other CPUs, which minimizes spinning. So don&#39;t use spinlocks to protect large critical sections.</p>
<p>Spin Locks</p>
<ul class="list">
<li><code>void spinlock_init(struct spinlock *lk)</code></li>
<li><code>void spinlock_acquire(struct spinlock *lk)</code></li>
<li><code>void spinlock_release(struct spinlock *lk)</code></li>
<li><code>bool spinlock_do_i_hold(struct spinlock *lk)</code></li>
<li><code>void spinlock_cleanup(struct spinlock *lk)</code></li>
</ul>
<p>Locks</p>
<ul class="list">
<li><code>struct lock *lock_create(const char *name)</code></li>
<li><code>void lock_acquire(struct lock *lk)</code></li>
<li><code>void lock_release(struct lock *lk)</code></li>
<li><code>bool lock_do_i_hold(struct lock *lk)</code></li>
<li><code>void lock_destroy(struct lock *lk)</code></li>
</ul>
<h2 id="wait-channels"><a class="header-link" href="#wait-channels"></a>Wait Channels</h2>
<p>When a thread blocks, it stops running, i.e. stops using the processor.</p>
<pre class="hljs"><code><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">wchan_sleep</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> wchan *wc)</span></span>;     <span class="hljs-comment">// blocks calling thread on wait channel wc</span>

<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">wchan_wakeall</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> wchan *wc)</span></span>;   <span class="hljs-comment">// unblock all threads sleeping on wait channel wc</span>

<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">wchan_wakeone</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> wchan *wc)</span></span>;   <span class="hljs-comment">// unblock one thread sleeping on wait channel wc</span>

<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">wchan_lock</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> wchan *wc)</span></span>;      <span class="hljs-comment">// prevent operations on wait channel wc</span></code></pre><h2 id="semaphore"><a class="header-link" href="#semaphore"></a>Semaphore</h2>
<p>is a synchronization primitive that can be used to enforce mutual exclusion requirements. It can also be used to solve other kinds of synchronization problems.</p>
<p>It&#39;s an object has an integer value which supports two operations:</p>
<ul class="list">
<li><strong>P</strong>: if the semaphore value is greater than 0, decrement it. Otherwise, wait until the value is greater than 0 and then decrement it.</li>
<li><strong>V</strong>: : increment the value of the semaphore</li>
</ul>
<p>By defn, <code>P</code> and <code>V</code> operations of a semaphore are atomic.</p>
<p><strong>Difference between a lock and a semaphore</strong></p>
<ul class="list">
<li><code>V</code> does not have to follow <code>P</code></li>
<li>A semaphore can start with a count of 0</li>
<li>Calling <code>V</code> increments the semaphore by 1.</li>
<li>Semaphore do not have owners.</li>
</ul>
<p><strong>Producer/Consumer Synchronization with Bounded Buffer</strong></p>
<ol class="list">
<li>producers: threads that (create and) add items to a buffer</li>
<li>consumers: thread that remove (and process) items from the buffer</li>
</ol>
<h2 id="semaphore-implementation"><a class="header-link" href="#semaphore-implementation"></a>Semaphore Implementation</h2>
<pre class="hljs"><code><span class="hljs-keyword">struct</span> semaphore {
    <span class="hljs-keyword">char</span> *sem_name;             <span class="hljs-comment">// for debug purposes</span>
    <span class="hljs-keyword">struct</span> wchan *sem_wchan;    <span class="hljs-comment">// queue where threads wait</span>
    <span class="hljs-keyword">struct</span> spinlock sem_lock;   <span class="hljs-comment">// to synch access to this struct</span>
    <span class="hljs-keyword">volatile</span> <span class="hljs-keyword">int</span> sem_count ;    <span class="hljs-comment">// value of the semaphore</span>
};

<span class="hljs-function"><span class="hljs-keyword">void</span>
<span class="hljs-title">P</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> semaphore *sem)</span>
</span>{
        KASSERT(sem != <span class="hljs-literal">NULL</span>);
        KASSERT(curthread-&gt;t_in_interrupt == <span class="hljs-literal">false</span>);

    spinlock_acquire(&amp;sem-&gt;sem_lock);
        <span class="hljs-keyword">while</span> (sem-&gt;sem_count == <span class="hljs-number">0</span>) {       <span class="hljs-comment">// prepare to sleep</span>
            wchan_lock(sem-&gt;sem_wchan);
            spinlock_release(&amp;sem-&gt;sem_lock);
            wchan_sleep(sem-&gt;sem_wchan);    <span class="hljs-comment">// sleep</span>
            spinlock_acquire(&amp;sem-&gt;sem_lock);
        }
        KASSERT(sem-&gt;sem_count &gt; <span class="hljs-number">0</span>);
        sem-&gt;sem_count--;                   <span class="hljs-comment">// claim one item</span>
    spinlock_release(&amp;sem-&gt;sem_lock);
}

<span class="hljs-function"><span class="hljs-keyword">void</span>
<span class="hljs-title">V</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> semaphore *sem)</span>
</span>{
        KASSERT(sem != <span class="hljs-literal">NULL</span>);

    spinlock_acquire(&amp;sem-&gt;sem_lock);

        sem-&gt;sem_count++;
        KASSERT(sem-&gt;sem_count &gt; <span class="hljs-number">0</span>);
    wchan_wakeone(sem-&gt;sem_wchan);

    spinlock_release(&amp;sem-&gt;sem_lock);
}
</code></pre><p>Incorrect Semaphore Implementation: Suppose <code>spinlock_release</code> preceeds <code>wchan_lock</code>... Thread 1 is blocked on a semaphore that has resources.</p>
<p>Instead Suppose <code>wchan_lock</code> preceeds <code>spinlock_release</code>.</p>
<h2 id="condition-variables"><a class="header-link" href="#condition-variables"></a>Condition Variables</h2>
<p>OS/161 supports another common synchronization primitive:
<strong>condition variables</strong>.</p>
<p>Each CV is intended to work together with a lock: only used from  within the critical section that is protected by the lock.</p>
<ol class="list">
<li><strong>wait</strong>: This causes the calling thread to block, and it releases the lock associated with the condition variable. Once the thread is unblocked it reacquires the lock.</li>
<li><strong>signal</strong>: If threads are blocked on the signaled condition variable, then one of those threads is unblocked.</li>
<li><strong>broadcast</strong>: Like signal, but unblocks all threads that are blocked on the condition variable.</li>
</ol>
<pre class="hljs"><code><span class="hljs-comment">// solution 1</span>
<span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">SafeToWalk</span><span class="hljs-params">()</span> </span>{
    lock_acquire(geeseMutex);
    <span class="hljs-keyword">while</span> (numberOfGeese &gt; <span class="hljs-number">0</span>) {
        lock_release(geeseMutex); <span class="hljs-comment">// allow access</span>
        <span class="hljs-comment">// allow some context switch to accur and another thread</span>
        <span class="hljs-comment">//   might then acq the lock and modify numberOfGeese</span>
        lock_acquire(geeseMutex); <span class="hljs-comment">// restrict access</span>
    }
    GoToClass();
    lock_release(geeseMutex);
}

<span class="hljs-comment">// soln2</span>
<span class="hljs-keyword">int</span> <span class="hljs-keyword">volatile</span> numberOfGeese = <span class="hljs-number">100</span>;
lock geeseMutex;
cv zeroGeese;
<span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">SafeToWalk</span><span class="hljs-params">()</span> </span>{
    lock_acquire(geeseMutex);
    <span class="hljs-keyword">while</span> (numberOfGeese &gt; <span class="hljs-number">0</span>) {
        cv_wait(zeroGeese, geeseMutex);
    }
    GoToClass();
    lock_release(geeseMutex);
}</code></pre><blockquote>
<p>Lesley&#39;s recordings start here.</p>
</blockquote>
<p>We left last class: semaphores and CV. Different primitives for concurrency problem.</p>
<ul class="list">
<li>Semaphore:<ul class="list">
<li>any number of resources. <code>P</code> acquire, <code>V</code> release. Use as a lock. Keep in mind it&#39;s not lock. There&#39;s no built-in protection for it, no track of ownership: someone else tries to release <strong>binary</strong> semaphore on me, they can, and we have race condition.</li>
<li><strong>counting</strong>: keep counting # of resources</li>
<li><strong>barrier</strong>: force one thread to wait for others to complete before we proceed. Not separate implementation.</li>
<li>keep in mind do not touch the counter directly. It&#39;s a shared resource.</li>
</ul>
</li>
<li>CV: you are inside critical section. You really need condition to be true to proceed. But the lock you own it the lock you are using to protect the shared variable that has unique value. CV lets us do simultaneously safely let go of the lock and fall asleep so that another thread can modify the condition and wake us back up.<br>
Most of the type we are using: when we are woken back up, we need to recheck the condition.</li>
</ul>
<h2 id="other-sources-of-race-conditions"><a class="header-link" href="#other-sources-of-race-conditions"></a>Other sources of Race conditions</h2>
<p>The previous RC is because of the code you wrote.</p>
<p><strong>memory models</strong> describe how thread access to memory in shared regions behave. a memory model tells the compiler and CPU which optimizations can be performed</p>
<p><strong>compiler</strong>: it does optimization. Reduce the # of assembly instrs: load and stores.</p>
<pre class="hljs"><code><span class="hljs-keyword">int</span> sharedTotal = <span class="hljs-number">0</span>;
<span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">FuncA</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-comment">//... code that uses sharedTotal ...</span>
}
<span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">FuncB</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-comment">//... code that uses sharedTotal ...</span>
}</code></pre><p>Instead of go to RAM, much more efficient to keep it in register: register allocation. Here&#39;s the problem: It doesn&#39;t know if A and B run at the same time. If one put in <code>$3</code> one in <code>$8</code>. Big race condtion. There are also others optimization.</p>
<p>Always load/store var from RAM, not reordering: <code>volatile</code>. Disable compiler optimizations, but not solve race conditions in your codes.</p>
<p><strong>CPU</strong>: fetch the program counter, decode it, execute it and move on. But it&#39;s more complex: pipeline, branch prediction, reorder instrs... It also has memory model and so that you can notify the CPU: multi-threaded code is going on here. Barrier or fence instrs to entry gate: CPU stops rearranging. And until end gate, turn on opt back on. Don&#39;t need to worry in OS161.</p>
<div class='ex'>
    <div class="ex-title">In class problem: semaphore to CV</div>
    <div class='ex-content'>
<table>
    <thead>
        <tr>
            <th>Global Vars</th>
            <th>Initialization</th>
            <th>Function <code>func1</code></th>
            <th>Function <code>func2</code></th>
        </tr>
    </thead>
<tbody>
<tr>
<td>
<pre>
struct semaphore *sa;
struct semaphore *sb;
struct semaphore *sc;
</pre>
</td>
<td>
<pre>
sa = sem_create(&quot;A&quot;, 1);
sb = sem_create(&quot;B&quot;, 1);
sc = sem_create(&quot;C&quot;, 0);
</pre>
</td>
<td>
<pre>
void func1() {
    P(sa);
    funcA();
    V(sa);
    P(sc);
}
</pre>
</td>
<td>
<pre>
void func2() {
    P(sb);
    funcB();
    V(sb);
    P(sc);
}
</pre>
</td>
</tr>
</tbody>
</table>

Re-implement <code>func1</code> and <code>func2</code> using lock and cv.
<br><br>
<strong>Solution</strong>: func1 is consumer, func2 is producer.
<br>
<pre>
<code>
lock A, B, C;
CV cv;
count = 0;

func1 {
    lock_acq(A)
        funcA()
    lock_rel(A)

    lock_acq(C)
        count--
        if (count &lt; 0) cv_wait(cv, C)
    lock_rel(C)
}

func2 {
    lock_acq(B)
        funcB()
    lock_rel(B)

    lock_acq(C)
        if (count &lt; 0) cv_signal(cv, C)
        count++
    lock_rel(C)
}
</code>
</pre>
    </div>
</div>




<h2 id="deadlocks"><a class="header-link" href="#deadlocks"></a>Deadlocks</h2>
<pre class="hljs"><code>lock lockA, lockB;

<span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">FuncA</span><span class="hljs-params">()</span> </span>{
    lock_acquire(lockA)
    lock_acquire(lockB)
    ...
    lock_release(lockA)
    lock_release(lockB)
}

<span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">FuncB</span><span class="hljs-params">()</span> </span>{
    lock_acquire(lockB)
    lock_acquire(lockA)
    ...
    lock_release(lockB)
    lock_release(lockA)
}</code></pre><ul class="list">
<li>Thread 1 executes <code>lock_acquire(lockA)</code></li>
<li>Thread 2 executes <code>lock_acquire(lockB)</code></li>
<li>Thread 1 executes <code>lock_acquire(lockB)</code></li>
<li>Thread 2 executes <code>lock_acquire(lockA)</code></li>
</ul>
<p>Deadlock only shows up under certain order of thread execution. It is very difficult to detect: between problematic wait and wait on purpose.</p>
<p>Generally, it happens when multiple threads, each acquire multiple resources.</p>
<ol class="list">
<li>don&#39;t try to aquire a lock if you have already owned.</li>
<li>Two strategies</li>
</ol>
<p><strong>No hold and wait</strong>: while you own the resources, no wait (no block, no spin).
<br> Being able to aquire all resources at once. We need special implementation of lock to support.</p>
<p>If you can&#39;t acq a lock, you can&#39;t fall asleep. Special implementation of acq.</p>
<pre class="hljs"><code><span class="hljs-comment">// true if you get the lock</span>
<span class="hljs-comment">// false if cannot, but do not go to sleep.</span>
<span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">try_acq</span><span class="hljs-params">(lk)</span> </span>{
    acq(lk-&gt;spin)
        <span class="hljs-keyword">if</span> (lk-&gt;held) {
            release(lk-&gt;spin)
            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>
        }
        lk-&gt;held =  <span class="hljs-literal">true</span>
        lk-&gt;owner = me
    release(lk-&gt;spin)
    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>
}</code></pre><p>Solution to previous deadlock:</p>
<pre class="hljs"><code>acq(A) <span class="hljs-comment">// I own nothing and safely acquire</span>

<span class="hljs-keyword">while</span> (!try_acq(B)) {
    release(A)
    <span class="hljs-comment">// if you want to improve the performance, put yield here</span>
    acq(A)
}</code></pre><p>But it&#39;s nasty if we want acq lots of things, also it&#39;s spinning.</p>
<p><strong>Resource ordering</strong>: assign every single resource a single number. Acquire them only in strictly increasing order. There&#39;s problem if different programmers have different rules.</p>
<div class='ex'>
<div class="ex-title">
In class problem: queuexfer
</div>

<div class='ex-content'>
Suppose that a threaded program has N queues of items. The program needs to support an operation called <code>Transfer(i,j)</code>. Each call to <code>Transfer</code> will transfer a single item from the i-th queue to the jth queue,
unless there is nothing in the i-th queue, in which case the call will not affect the queues.
<br>The program will have multiple concurrent threads, each of which may call <code>Transfer</code> zero or more times.
<br>How would you use locks to ensure that <code>Transfer</code> operations are atomic? Specifically, how many locks
would you use, what would each lock protect, and when would the locks be acquired and released to ensure
that transfers are atomic?

<br><br>
One way: no hold and wait. Downside: cannot both lock at the same time, busy wait: spin.

<br><br>
Alternate: resource ordering.
<pre>
<code>
Transfer(Q_a, Q_b) {
    // check resource number
    if (a &lt; b) {
        acq(qa)
        acq(qb)
    } else {
        acq(qb)
        acq(qa)
    }
}
</code>
</pre>
Downside: you need to sort if you acq all resources \(\Theta(n\log n)\).
</div>
</div>





<h1 id="process"><a class="header-link" href="#process"></a>Process</h1>
<p>is an is an environment in which an application program runs.</p>
<p>includes virtualized resources that its program can use: one (or more) threads</p>
<p>each program’s process <em>isolates</em> it from other programs in other processes</p>
<h2 id="fork"><a class="header-link" href="#fork"></a>fork</h2>
<p>creates a brand new process (the child) that is a clone of the original (the parent)</p>
<ul class="list">
<li>new process structure</li>
<li>new address space</li>
<li>new thread array</li>
<li>new PID
clone</li>
<li>content of address space</li>
</ul>
<h2 id="_exit"><a class="header-link" href="#_exit"></a>_exit</h2>
<p>terminate the calling process. Not necessarily disappear: stop executing, address space get cleaned, but if it has parents, that parent is alive. Parents want to figure out why child dies. Leave behind a msg for parent.</p>
<h2 id="waitpid"><a class="header-link" href="#waitpid"></a>waitpid</h2>
<p>offer synchronization between processes. Cause the caller to wait for the PID process to terminate. Restricted to: parent can only wait for their children to die.</p>
<p>Children cannot wait for their parents. If they die, they are old.</p>
<h2 id="execv"><a class="header-link" href="#execv"></a>execv</h2>
<p>Now, the last of the five system calls: execv. It does not create a new process.</p>
<p>It changes the program and a existing process is running. Process structure is same, but the address space has changed.</p>
<p><code>Hello world</code> program, and call <code>execv matlab</code>.</p>
<p>Create a new address space, and load the program into the new address space.</p>
<p>Parent child relationship: If you go home tonight, and dye your hair in green, your parent may not like it. But they cannot change genetically they are your parents. The same is true for processes: you can change the program that you are running but you cannot change parent-child relationship.</p>
<p>Example from slides:</p>
<pre class="hljs"><code><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span>
</span>{
    <span class="hljs-keyword">int</span> rc = <span class="hljs-number">0</span>;
    <span class="hljs-keyword">char</span> *args[<span class="hljs-number">4</span>];

    args[<span class="hljs-number">0</span>] = (<span class="hljs-keyword">char</span> *) <span class="hljs-string">"/testbin/argtest"</span>;
    args[<span class="hljs-number">1</span>] = (<span class="hljs-keyword">char</span> *) <span class="hljs-string">"first"</span>;
    args[<span class="hljs-number">2</span>] = (<span class="hljs-keyword">char</span> *) <span class="hljs-string">"second"</span>;
    args[<span class="hljs-number">3</span>] = <span class="hljs-number">0</span>; <span class="hljs-comment">// null terminator</span>

    rc = execv(<span class="hljs-string">"/testbin/argtest"</span>, args); <span class="hljs-comment">// takes two parameters</span>
    <span class="hljs-built_in">printf</span>(<span class="hljs-string">"If you see this execv failed\n"</span>);
    <span class="hljs-built_in">printf</span>(<span class="hljs-string">"rc = %d errno = %d\n"</span>, rc, errno);
    <span class="hljs-built_in">exit</span>(<span class="hljs-number">0</span>);
}</code></pre><p>takes two parameters. Many times you need command line arguments. Array of pointers.</p>
<p><code>execv</code> if it succeeds, does not return. Because it successfully created the new address space and new program. We successfully loaded the program into it. The calling program will not exist if <code>execv</code> succeeded. The only time it returns is when it fails. Why would it fail? 30mb ram then run Matlab. It&#39;s possible that there&#39;s no memory left or you call the program wrongly. When you write your <code>execv</code>, you need to test for these error cases and return appropriate error codes. (but cs350 stuff don&#39;t have such tests on these).</p>
<p>You notice that we can&#39;t tell how many arguments there are automatically. So we use null terminator array and you are responsible for counting.</p>
<p>Another example. This time with fork.</p>
<pre class="hljs"><code><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span>
</span>{
    <span class="hljs-keyword">char</span> *args[<span class="hljs-number">4</span>];
    <span class="hljs-comment">/* set args here */</span>
    rc = fork(); <span class="hljs-comment">/* returns 0 to child, pid to parent */</span>
    <span class="hljs-keyword">if</span> (rc == <span class="hljs-number">0</span>) {
        status = execv(<span class="hljs-string">"/testbin/argtest"</span>,args);
        <span class="hljs-built_in">printf</span>(<span class="hljs-string">"If you see this execv failed\n"</span>);
        <span class="hljs-built_in">printf</span>(<span class="hljs-string">"status = %d errno = %d\n"</span>, status, errno);
        <span class="hljs-built_in">exit</span>(<span class="hljs-number">0</span>);
    } <span class="hljs-keyword">else</span> {
        child_pid = rc;
        parent_code();
        p = waitpid(child_pid,&amp;child_exit,<span class="hljs-number">0</span>);
    }
}</code></pre><p>Now I have two processes. Even though they are separate, but their contents are identical with the exception of value of <code>rc</code>. 0 for child, pid for parent.</p>
<p>If child, <code>execv</code>. Child is running different process. Parent can still wait for child to terminate. Parent child relationship is not impacted by <code>execv</code> which stays forever.</p>
<p>Go home and write thread fork bomb.</p>
<h1 id="system-calls"><a class="header-link" href="#system-calls"></a>System Calls</h1>
<ul class="list">
<li>Process management calls, e.g., fork, are called by user programms. They are also system calls.</li>
<li><strong>System calls</strong> are the interface between user processes and the kernel.</li>
<li>The kernel code runs at the highest privilege level, where any CPU instructions can be executed.</li>
<li>Program in user space cannot execute code or instructions belonging to a higher-level of privilege.</li>
</ul>
<h2 id="kernel-privilege"><a class="header-link" href="#kernel-privilege"></a>Kernel Privilege</h2>
<p>The CPU implements different levels (or rings) of execution
privilege as a security and isolation mechanism. Kernel code at highest level.</p>
<p><strong>Key Question</strong>: Since application programs cannot directly call the
kernel, how does a program make a system call such as <code>fork</code>?</p>
<ol class="list">
<li>Interrupts<ul class="list">
<li>Interrupts are raised by devices (hardware)</li>
<li>An interrupt causes the CPU to transfer control to a fixed location in memory (specified by the designers of the CPU) where an interrupt handler must be located.</li>
<li>Interrupt handlers are part of the kernel.</li>
</ul>
</li>
<li>Exceptions<ul class="list">
<li>conditions that occur during the execution of a program instruction.</li>
<li>The CPU handles exceptions like it handles interrupts:<ul class="list">
<li>Control is transferred to a fixed location, where an exception handler is located.</li>
<li>The processor switches to privileged execution mode.</li>
</ul>
</li>
<li>In OS/161 <em>the same routine is used to handle exceptions and interrupts</em>.</li>
</ul>
</li>
</ol>
<p>When CPU receives interrupt or exception, your program stops executing and exception/interrupt handler is called, part of kernel code. Then CPU switches from unprivileged mode to privileged mode, so now we can execute kernel&#39;s code. Produces the trapframe: storing every single reg value (including special ones) so we can return to the exact point of program execution after we handle.</p>
<p>Extra: <a href="https://meltdownattack.com/">Spectre and Meltdown Papers</a>.</p>
<p><strong>Key Question</strong>: There is only one <code>syscall</code> exception, <code>EX_SYS</code>. So how does the OS distinguish between a <code>fork</code> and <code>getpid</code> system call?</p>
<p><em>system call codes</em></p>
<ul class="list">
<li>The kernel expects the code to be placed in a specified location before executing <code>syscall</code> (for OS/161 on MIPS, reg <code>v0</code>)</li>
<li>the codes and code location are part of the kernal ABI (Application Binary Interface)</li>
</ul>
<p>ABI is not secret because we need user land to know that info and it absolutely tells nothing what&#39;s happening in the kernel -- blackbox.</p>
<p>Example:</p>
<ul class="list">
<li><code>li v0, 0</code> where 0 is the syscall code for <code>fork</code>.</li>
<li>Syscall parameters: load into regs <code>a0</code> to <code>a3</code>. If more, put into stack or heap, and put the address here.</li>
<li>Use <code>syscall</code> to raise exception.</li>
</ul>
<p>Return two values:</p>
<ul class="list">
<li>reg <code>a3</code>: success/fail</li>
<li>reg <code>v0</code>: return value/error code</li>
</ul>
<h2 id="user-and-kernel-stacks"><a class="header-link" href="#user-and-kernel-stacks"></a>User and Kernel Stacks</h2>
<p>Every OS/161 process thread has <strong>two</strong> stacks, although it only uses one at a time.</p>
<p>The only thing that goes into user stack us the user application stack. But before we save the trapframe, we must change the stack pointer from user stack to kernel stack.</p>
<ol class="list">
<li>The User (Application) Stack is used while the thread is executing application code.<ul class="list">
<li>Saw this in <a href="/19-05/CS241/">CS 241</a>.</li>
<li>The kernel creates this stack when it sets up the virtual address space for the process (or thread if the OS supports multi-threaded code).</li>
</ul>
</li>
<li>The Kernel Stack is used while the thread is executing kernel code, i.e. after an exception or interrupt.<ul class="list">
<li>This stack is a kernel structure (i.e. it is located in the kernel’s address space).</li>
<li>It also holds trap frames and switch frames (because it is the kernel that creates trap frames and switch frames)</li>
</ul>
</li>
</ol>
<h2 id="exception-handling"><a class="header-link" href="#exception-handling"></a>Exception Handling</h2>
<ul class="list">
<li>first to run assembly code, <code>common_exception</code><ul class="list">
<li>save stack pointer</li>
<li>switches SP to point to the thread&#39;s kernel stack,</li>
<li>carefully saves app state and address of the instruction,</li>
<li>calls <code>mips_trap</code>, passing a pointer to the trap frame as an arg.</li>
</ul>
</li>
<li>After <code>mips_trap</code> is finished, the <code>common_exception</code> handler will<ul class="list">
<li>restore application&#39;s state</li>
<li>jump back to application instruction that was interrupted and switch back to unprivileged execution mode.</li>
</ul>
</li>
<li>See <code>kern/arch/mips/locore/exception-mips1.S</code> (assembly file)</li>
</ul>
<h3 id="mips_trap"><a class="header-link" href="#mips_trap"></a>mips_trap</h3>
<p>determines what type of exception it is by looking at the exception code.</p>
<p>(there is a separate handler in the kernel for each type of exception.) Based on that exception code, call appropriate handler.</p>
<ul class="list">
<li>interrupt? call <code>mainbus_interrupt</code></li>
<li>address translation exception? <code>vm_fault</code></li>
<li>system call? call <code>syscall</code> (kernel function), passing it the trap
frame pointer</li>
<li><code>kern/arch/mips/syscall/syscall.c</code></li>
</ul>
<p>See <code>kern/arch/mips/locore/trap.c</code></p>
<p><strong>One important thing</strong>: when exception raised, one of the first thing <code>common_exception</code> does it to disable the interrupt on CPU. When we call <code>mips_trap</code>, interrupt exceptions are off for now.</p>
<ul class="list">
<li>If it was actually an interrupt, they stay off until  the hardware has been handled.</li>
<li>If not, don&#39;t have to call <code>mainbus_interrupt</code> to handle it, then we are ok to be interrupted again. It is not hardware interrupt, then we take interrupt exceptions back on.</li>
</ul>
<p><strong>increase program counter</strong>: if we don&#39;t do this, the system call exception will be raised over and over again. We are halting execution and doing sth else, thus we need manully. 4 byte.</p>
<p>Kernel is just a program, a sequence of instructions.</p>
<p>Two type of calls:</p>
<ul class="list">
<li>procedure calls: used by apps to execute other application code,</li>
<li>sys calls: exec kernel code.</li>
</ul>
<h2 id="multiprocessing"><a class="header-link" href="#multiprocessing"></a>Multiprocessing</h2>
<p>or multitasking.</p>
<ul class="list">
<li>The OS ensures that <em>processes are isolated from one another</em>.</li>
<li>Interprocess communication should be possible.</li>
<li>all processes must share the available hardware resources. \(\implies\) This sharing is coordinated by the operating system.</li>
</ul>
<p>Keep in mind, it&#39;s not processes that run. Threads execute. Process has to have a thread in order to execute, so we really are talking about multithreads. Now we have a pool of threads, which belong to different processes. Only when quantum expires, we do context switch. (Timer interrupt)</p>
<h2 id="stack-diagrams"><a class="header-link" href="#stack-diagrams"></a>Stack Diagrams</h2>
<p>In the next few minutes, I&#39;m gonna show you stack diagrams because you&#39;d better bet they are going to show up on your exams.</p>
<p><code>mips_trap</code>&#39;s job is to figure out what kind of exception that actually raised. Then call the handler that is specific to this exception. Now we are going to execute <code>mips_trap</code>. Now after we check that if it&#39;s an interrupt or not, then it realizes that it is not an interrupt, then <code>mips_trap</code> will turn exceptions and interrupts back on. It means that while we are executing our sys call, we CAN be interrupted. KEEP THAT IN MIND.</p>
<p>Look at <code>v0</code> and that&#39;s going to tell you which syscal we actually want to run (a great big old <code>switch</code> statement). We want <code>sys_fork</code>. Now interrupts are on which means you can be preempted while executed this fork.</p>
<p>So now what happens to our stack: If we have a timer interrupt. First thing you see is trap frame (produced by <code>common_exception</code>). Push a trapframe onto the kernel stack. Since we are already in privilege mode and on kernel stack, you actually know the <code>common_exception</code> code. If we are on kernel stack, we don&#39;t do anything but just save the trapframe right. Then call <code>mips_trap</code> to figure out what just happened. It&#39;s <code>mainbus_interrupt</code>. It&#39;s hardware interrupt. While they are handling interrupts from hardware, we don&#39;t want to handle other hardware interrupts because this is the behaviour that is outside the control that thread is running and we don&#39;t to disrupt it for too long so generally leave it off.</p>
<p>In <code>mainbus_interrupt</code>, we discover it&#39;s the clock. Call interrupt handler for the clock: exceed schedule quantum, I&#39;d better preempt you. So call <code>thread_yield</code> -&gt; <code>thread_switch</code> -&gt; <code>switch_frame</code>. Context switch occurs. Popping off the stack, then returns to ... Then go back to <code>common_exception</code> where we restore the trapframe. Btw, we are turning the interrupts back on. Then back to user stack, reset the CPU back to unprivileged mode and now we go back to have a process to thread running its regular user mode. Similar to multithreads, but we have two stacks.</p>
<p>Now suppose we don&#39;t have interrupt. Return to syscall. At the very end of syscall, set return value and success/failure values for that system. Zero: success; One: failure. The last thing in syscall dispatcher（调度）, <strong>increment program counter</strong> because when the exception is raised we didn&#39;t actually increment it.</p>
<pre class="hljs"><code><span class="hljs-keyword">if</span> (err) { <span class="hljs-comment">/* err */</span>
    tf-&gt;tf_v0 = err;
    tf-&gt;tf_a3 = <span class="hljs-number">1</span>;
} <span class="hljs-keyword">else</span> { <span class="hljs-comment">/* no err */</span>
    tf-&gt;tf_v0 = retval;
    tf-&gt;tf_a3 = <span class="hljs-number">0</span>;
}

<span class="hljs-comment">/* advance PC */</span>
tf-&gt;tf_epc += <span class="hljs-number">4</span>;</code></pre><p><code>mips_trap</code> returns to <code>common_exception</code>. The trapframe data is
restored. Switch from kernel to user stack. Switch to unprivileged
mode (<code>rfe</code>: magical instruction). User code continues execution.</p>
<ul class="list">
<li>These diagrams are always on either midterm or final.</li>
<li>It is not possible for you to have two track frames back-to-back in OS/161. Reason for that is because when the exception is raised at the CPU, interrupts are turned off and they do not come back on again until at least halfway through <code>mips_trap</code> which means that each trapframe must be separated by at least <code>mips_trap</code>.</li>
</ul>
<h2 id="inter-process-communication-(ipc)"><a class="header-link" href="#inter-process-communication-(ipc)"></a>Inter-Process Communication (IPC)</h2>
<p>Processes can talk to each other. IPC is a family of methods used to send data between processes.</p>
<p>File, Socket, Pipe, Shared Memory, Message Passing/Queue.</p>
<div class='ex'>
<div class="ex-title">
In-Class Problems: procfork
</div>

<div class='ex-content'>
<p>
<strong>Question 1</strong>: What output will be generated by the parent and child processes for the program shown
below?
</p>

<pre>
<code>
int x; /* global variable */
int main()
{
    int rc;
    x = 0;
    rc = fork();
    if (rc == 0) {
        x = 10;
        printf(&quot;A: %d\n&quot;, x);
    } else {
        printf(&quot;B: %d\n&quot;, x);
        x = 100;
    }
    printf(&quot;C: %d\n&quot;, x);
}
</code>
</pre>
<p><strong>Solution</strong>:<br></p>
<ul class="list">
<li>Parent: B: 0, C: 100</li>
<li>Child: A: 10, C: 10</li>
</ul>

<p> <strong>Question 2</strong>: Consider a system with a process, <code>ProcA</code>, that executes the program below. Draw the tree
rooted at <code>ProcA</code> representing the processes created by this program. Every node in the tree should represent
a process, and there should be an edge from node A to node B if process A creates process B. Label each
node of the tree with the label of the <code>fork()</code> system call that created it.</p>
<pre>
<code>
int main () {
    fork(); /* Label: B */
    fork(); /* Label: C */
    fork(); /* Label: D */
    return 0;
}
</code>
</pre>

<img src="/pics/procfork.svg" width=100%>

<p>Note that the process name here doesn&#39;t matter...</p>
</div>
</div>

<h1 id="virtual-memory"><a class="header-link" href="#virtual-memory"></a>Virtual Memory</h1>
<p><strong>Physical addresses</strong> are provided directly by the hardware, i.e. the amount of installed RAM. One PA space per computer.</p>
<p><strong>Virtual addresses (or logical addresses)</strong> are addresses provided by the OS to the processes. One VA space per process.</p>
<p>The conversion of a virtual address to a physical address is called <strong>address translation</strong>.</p>
<p>The OS provides each process with illusion that it has a large amount of continuous memory available  exclusively to itself, i.e. and <strong>address space</strong>.</p>
<p>The goals are</p>
<ul class="list">
<li>to efficiently translate between virtual and physical addresses,</li>
<li>to provide transparency so the programmer does not need to worry about the difference,</li>
<li>to protect one process’s address space from other (perhaps buggy) processes.</li>
</ul>
<p>We here use \(P\): Physical memory takes \(P\) bits to specify the physical address of each type, then the
maximum amount of addressable physical memory is \(2^P\) bytes.</p>
<p>In Sys/161, it uses \(P=32\), 32-bit physical addresses. In slide \(P=18\).</p>
<table>
<thead>
<tr>
<th style="text-align:center">Address Space</th>
<th style="text-align:center">Size of Address space (\(s\))</th>
<th style="text-align:center">Num of Bits Needed for (\(b\))</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">0 1</td>
<td style="text-align:center">2</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">00 01 10 11</td>
<td style="text-align:center">4</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">000 001 010 100 011 101 110 111</td>
<td style="text-align:center">8</td>
<td style="text-align:center">3</td>
</tr>
</tbody>
</table>
<p>Use the formula \(b=\log_2(s)\) and \(s=2^b\).</p>
<h2 id="virtual-memory-&-address-translation"><a class="header-link" href="#virtual-memory-&-address-translation"></a>Virtual Memory &amp; Address Translation</h2>
<p>Similarly, we have \(V\) bits for virtual addresses.</p>
<p>For MIPS \(V=32\). In slide \(V=16\).</p>
<p>Running applications only see virtual addresses. Each process is isolated in its virtual memory and cannot access another process’s virtual memory.</p>
<p>Virtual memory is used to</p>
<ul class="list">
<li><em>isolate</em> processes from each other and from the kernel,</li>
<li>potentially support virtual memory that <em>is larger</em> than physical memory.</li>
</ul>
<p>Each virtual memory address is mapped to a different part of physical memory.</p>
<p>Address translation is performed in hardware, in the <strong>Memory Management Unit (MMU)</strong>, using information provided by the kernel.</p>
<p>We will consider a series of five increasingly more sophisicated methods of address translation.</p>
<h3 id="1.-dynamic-relocation"><a class="header-link" href="#1.-dynamic-relocation"></a>1. Dynamic Relocation</h3>
<p>The virtual address of each process is translated using two values:</p>
<ol class="list">
<li><strong>offset</strong> or relocation (R): addr in physical memory where the process’s memory begins</li>
<li><strong>limit</strong> (L): the amount of memory used by the process.</li>
</ol>
<p>MMU does the following calculation</p>
<pre class="hljs"><code><span class="hljs-keyword">if</span> (v &lt; limit) <span class="hljs-keyword">then</span>
    p ← v + offset
<span class="hljs-keyword">else</span>
    <span class="hljs-keyword">raise</span> memory <span class="hljs-keyword">exception</span></code></pre><div class='ex'>
<div class="ex-title">
Dynamic Relocation Example
</div>

<div class='ex-content'>
<table>
    <thead>
        <tr>
            <th>Process A</th>
            <th>Process B</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Limit Reg: 0x7000. <br>Reloc Reg: 0x24000.</td>
            <td>Limit Reg: 0xC000. <br>Reloc Reg: 0x13000.</td>
        </tr>
        <tr><td></td><td></td></tr>
        <tr>
        <td>
        <table>
            <tbody>
                <tr>
                    <td><strong>v=?</strong></td>
                    <td><strong>p=?</strong></td>
                </tr>

                <tr>
                    <td>0x102C</td>
                    <td>0x2520C</td>
                </tr>
                <tr>
                    <td>0x8000</td>
                    <td>Exception</td>
                </tr>
                <tr>
                    <td>0x0000</td>
                    <td>0x24000</td>
                </tr><br>            </tbody>
        </table>
        </td>
<td>
<table>
<tbody>
    <tr>
        <td><strong>v=?</strong></td>
        <td><strong>p=?</strong></td>
    </tr>
        <tr>
            <td>0x102C</td>
            <td>0x1420C</td>
        </tr>
        <tr>
            <td>0x8000</td>
            <td>0x1B000</td>
        </tr>
        <tr>
            <td>0x0000</td>
            <td>0x13000</td>
        </tr><br>    </tbody>
</table>
</td>
</tr>
    </tbody>
</table>
</div>
</div>

<p>However, this suffers from <strong>fragmentation</strong>.</p>
<p>Using just two registers per process, dynamic relocation: allows multiple processes to share RAM and isolates each process’s address space from all other processes.</p>
<h3 id="2.-segmentation"><a class="header-link" href="#2.-segmentation"></a>2. Segmentation</h3>
<p><a href="https://www.geeksforgeeks.org/segmentation-in-operating-system/">Extra Reading</a></p>
<p>Instead of mapping the entire virtual memory to physical memory, we map each <strong>segment</strong> of the address space separately. The kernel maintains an offset and limit value for each segment. With segmentation, a virtual address can be thought of as having
two parts: (segment ID, offset within segment)</p>
<p>With \(K\) bits for segment ID, we can have up to</p>
<ul class="list">
<li>\(2^K\) segments</li>
<li>\(2^{V-K}\) bytes per segment</li>
</ul>
<p>So if there are 4 segments, then \(\log 4=2\) bits are required to represent the segment number and the maximum size of each segment is \(2^{V-2}\) btyes.</p>
<p>Fragmentation of physical memory is still possible.</p>
<p>Many approaches for translation.</p>
<p><strong>Approach 1</strong>: MMU has a relocation register and a limit register for each segment</p>
<ul class="list">
<li>for \(i\)th segment, \(R_i\) be the relocation offset and \(L_i\) be the limit.</li>
<li>To translate <code>v</code> to <code>p</code>:</li>
</ul>
<pre class="hljs"><code>s ← SegmentNumber(v)
<span class="hljs-selector-tag">a</span> ← AddressWithinSegment(v)

<span class="hljs-keyword">if</span> (<span class="hljs-selector-tag">a</span> ≥ limit[s]) then
    raise memory exception
<span class="hljs-keyword">else</span>
    <span class="hljs-selector-tag">p</span> ← <span class="hljs-selector-tag">a</span> + offset[s]</code></pre><div class='ex'>
<div class="ex-title">
Segmented Address Translation Example
</div>

<div class='ex-content'>
<p><strong>Process A</strong></p>
<table>
<thead>
<tr>
    <th>Segment</th>
    <th>Limit Register</th>
    <th>Relocation Register</th>
</tr>
</thead>
<tbody>
<tr>
    <td>0</td>
    <td>0x2000</td>
    <td>0x38000</td>
</tr>
<tr>
    <td>1</td>
    <td>0x5000</td>
    <td>0x10000</td>
</tr>
</tbody>
</table>

<p><strong>Process B</strong></p>
<table>
<thead>
<tr>
    <th>Segment</th>
    <th>Limit Register</th>
    <th>Relocation Register</th>
</tr>
</thead>
<tbody>
<tr>
    <td>0</td>
    <td>0x3000</td>
    <td>0x15000</td>
</tr>
<tr>
    <td>1</td>
    <td>0xB000</td>
    <td>0x22000</td>
</tr>
</tbody>
</table>

<p>Now translate the following for process A and B. (Process B is not done here)</p>

<p>For process A</p>
<table>
<thead>
<tr>
    <th>v</th><th>Segment</th><th>Offset (<code>a</code> in the code above)</th><th>p</th>
</tr>
</thead>
<tbody>
<tr>
    <td>v=0x1240</td><td>0</td><td>0x1240</td><td>0x39240</td>
</tr><tr>
    <td>v=0xA0A0</td><td>1</td><td>0x20A0</td><td>0x120A0</td>
</tr><tr>
    <td>v=0x66AC</td><td>0</td><td>0x66AC</td><td>Exception</td>
</tr><tr>
    <td>v=0xE880</td><td>1</td><td>0x6880</td><td>Exception</td>
</tr>
</tbody>
</table>

<p>
The first bit of VA specifies the segment. The next <strong>three bits</strong> specifies the <strong>first hexdigit</strong> of the offset and the
rest the virtual address specifies the rest of the offset.
</p>

<p>
Note that you would need to expand first hex digit into binary in order to see the seg number...
</p>
</div>
</div>

<p><strong>Approach 2</strong>: Maintain a segment table</p>
<p class="img-container"><img src="/pics/seg_table.png" width=100%></p>
<pre class="hljs"><code>If <span class="hljs-keyword">the</span> <span class="hljs-keyword">segment</span> <span class="hljs-built_in">number</span> <span class="hljs-keyword">in</span> v is greater than <span class="hljs-keyword">the</span> <span class="hljs-built_in">number</span> <span class="hljs-keyword">of</span> <span class="hljs-keyword">segments</span>
<span class="hljs-keyword">then</span>
    raise <span class="hljs-keyword">an</span> exception
<span class="hljs-keyword">else</span>
    use <span class="hljs-keyword">the</span> <span class="hljs-keyword">segment</span> <span class="hljs-built_in">number</span> <span class="hljs-built_in">to</span> lookup <span class="hljs-keyword">the</span> limit <span class="hljs-keyword">and</span> relocation values <span class="hljs-built_in">from</span> <span class="hljs-keyword">the</span> <span class="hljs-keyword">segment</span> table.</code></pre><div class='ex'>
<div class="ex-title">
Segmented Address Translation Example
</div>

<div class='ex-content'>
Virtual addr = 32 bits, Physical addr = 32 bits, Offset = 28 bits

<pre>
<code>
Segment Table base reg  0x0010 0000
Segment Table len reg   0x0000 0004
</code>
</pre>

<table>
<thead>
<tr>
    <th>Seg</th><th>Size</th><th>Protection</th><th>Start</th>
</tr>
</thead>
<tbody>
<tr>
    <td>0</td><td>0x6000</td><td>X-</td><td>0x7 0000</td>
</tr>
<tr>
    <td>1</td><td>0x1000</td><td>-W</td><td>0x6 0000</td>
</tr>
<tr>
<td>2</td><td> 0xC000</td><td> -W </td><td>0x5 0000</td>
</tr>
<tr>
<td>3</td><td> 0xB000</td><td> -W </td><td>0x8 0000</td>
</tr>
</tbody>
</table>

<pre>
<code>
Virtual address     0x0000 2004
Physical address =  <strong><strong>___</strong></strong> ?
Virtual address     0x2000 31A4
Physical address =  <strong><strong>___</strong></strong> ?
</code>
</pre>

<p>Split the virtual address <code>0x0000 2004</code> into the segment number <code>0x0</code> and the offset <code>0x000 2004</code></p>
<p>Check the segment number is not too large: <code>0x0 &lt; 0x4</code>. <code>0x4000 2004</code> would have a seg number too large.</p>
<p>Check that the offset is not too large: <code>0x000 2004 &lt; 0x6000</code>. <code>0x0000 6004</code> would have an offset that is too large.</p>
<p>Translate the segment number into a physical base address:
<code>SegmentTable[0x0] = 0x0007 0000.</code></p>
<p>Add the offset to physical base address to get the physical address:
<code>0x0007 0000 + 0x000 2004 = 0x0007 2004</code>.</p>
<br><br>
<p>
The answer for second one is <code>0x0005 31A4</code>.
</p>
<p><em>Side note</em>:
The difference between Virtual Addr and Offset (32-28 = 4 bits = 1 hex) is the number of bits for seg id.
</p>
<p>
If there were 8 segs in total, then we need \(\log_2 8\) bits to represent these 8 segs.
</p>
</div>
</div>

<p>No internal fragmentation.</p>
<p>Limitation: space for heap and stack is cannot grow beyond a
certain point, even though there is more memory available or
space between various segment gets wasted because it is too small
to fit anything (external fragmentation).</p>
<h3 id="3.-paging:-physical-memory"><a class="header-link" href="#3.-paging:-physical-memory"></a>3. Paging: Physical Memory</h3>
<p><strong>Key Idea</strong>: Divide Physical memory into fixed-size chunks called frames (a.k.a. physical pages).</p>
<p>Take physical memory, logically divide physical memory into fixed-sized chunks called <strong>frames</strong> (physical pages). Now our frames commonly, 4kb. size of physical memory divides frame size -&gt; # of frames.</p>
<p>Let&#39;s do the same thing with virtual memory. Take virtual memory and  divide into equal sized <strong>pages</strong>, programmatically, not physically.</p>
<p>Page size (virtual memory) must equal frame size (physical memory).</p>
<p>Now we get code segments: 7 pages in slides. Instead of getting contiguous, just ask RAM for any 7 pages. So we map every single page to whichever frame it&#39;s available.</p>
<p>We don&#39;t have to track the limit, but we do track of which frame the page map to. Any page can map to any frame ⇒ we will need a method to track this mapping, i.e. page tables.</p>
<p>Page table has an entry for every single page regardless whether we are using or not.</p>
<p>In our page table (for now), we will have</p>
<ul class="list">
<li>frame number: which frame is this page map to</li>
<li>valid bit: 1 if we are actually using this page. 0 if not.</li>
</ul>
<p>One register holds the addr of page table, stored in RAM.</p>
<p>This is virtual addr. Higher order bits, like segmentation, indicate which page. Remaining bits, page offset.</p>
<p>Extract the page number, use it to get an entry in page table. Check valid bit. 0 then throw exception. If 1, then do combination: physical address = (frame number × frame size) + offset.</p>
<p>The page offset is only related to the size of page. Number of Bits for Offset = log(Page Size).</p>
<p>Number of PTEs = Maximum Virtual Memory Size / Page Size</p>
<p>Number of Bits for Page Number = log(Number of PTEs)</p>
<p>Number of Bits for Frame Number = log(Number of Frames)</p>
<div class='ex'>
<div class="ex-title">
Paging: Address Translation Example
</div>

<div class='ex-content'>
<img src="/pics/page_table_trans.png" width=100%>

<p>
<strong>Process A</strong>: 0x2602C. Exception. 0xF024.
</p>
<p>
<strong>Process B</strong>: 0x1502C. 0x32800. 0x14024.
</p>
</div>
</div>

<p>We want to have some entries read-only, like code segment.</p>
<ul class="list">
<li>protection bit</li>
<li>reference (use) bit: has this PTE been used to translate any addr?</li>
<li>dirty bit: has any addr translation resulted in memory being written to particular page</li>
<li>present bit: is this page in RAM or not?</li>
</ul>
<p><em>How big are page tables?</em>
We have known # of PTEs. And size of each PTE. We take the product of these two.</p>
<p>Page tables can get very, very large.</p>
<p>Page tables are kernel data structures. They live in the kernel’s memory.</p>
<p>As the number of bits increases for our virtual addresses, it just doesn&#39;t scale at all.</p>
<p>Shrink the page table. Extra orgnization. We are going to turn it into a tree. There are no valid pages in that sub page table, do not make a table for it. There will be significantly fewer.</p>
<h3 id="4.-two-level-paging"><a class="header-link" href="#4.-two-level-paging"></a>4. Two-Level Paging</h3>
<p>Insteadd of four bits for page #, we are going to use 2 bits for first page # and 2 bits for second page #.</p>
<p>Instead of two parts address (page # and page offset), we now have multi-part address. We still have the <strong>same</strong> page offset which is only related to the page size. and a bunch of page numbers.</p>
<p>And our adress translation is the <strong>same</strong>:</p>
<pre class="hljs"><code>Physical <span class="hljs-built_in">Address</span> = Frame Number * Page Size + <span class="hljs-built_in">offset</span></code></pre><p>the look up is different.</p>
<div class='ex'>
<div class="ex-title">
Two-Level Paging Example
</div>

<div class='ex-content'>
<img src="/pics/2level_paging.png" width=100%>
<br>
Translate <code>0x58B4</code>.
<p>0x5 -&gt; <span style="color:red">01</span><span style="color:green">01</span> in binary</p>
<p>so we have \(p_1=01,p_2=01, \)offset=<code>8B4</code></p>
<p>The entry (frame number) for \(p_2=01\) in Table 2 is <code>0x12</code></p>
<p>Combine frame number 12 with the offset we get the physical address <code>0x128B4</code></p>
</div>
</div>

<h3 id="5.-multi-level-paging"><a class="header-link" href="#5.-multi-level-paging"></a>5. Multi-Level Paging</h3>
<p>We want each individual page table (dir, each subtable) exactly fit in <strong>one</strong> page. Since &quot;on demand paging&quot;  is very convenient. If we want to look for one table and it&#39;s not in memory, we only need to do one read from my disk.</p>
<p>So we can figure out how many levels we need to create multi-level tree. The goal is to reduce the size of individual page tables.</p>
<div class='ex'>
<div class="ex-title">
Levels Calculation
</div>

<div class='ex-content'>
\(V=40\), page size = 4KB (\(2^{12}\)) and PTE size = 4bytes (\(2^2\)) then
<p># of pages (and PTEs) = (virtual memory size)/(page size) = \({2^{40}/2^{12}}=2^{28}\) pages</p>
<p># of PTE&#39;s that can be stored on each page is (page size)/(PTE size) = \(2^{12}/2^2=2^{10}\) PTEs</p>
<p>How many page tables are needed? (# of PTEs)/(PTE&#39;s per page) = \(2^{28}/2^{10}=2^{18}\) page tables </p>
<p>So the top level page table (called the directory)</p>
<ul class="list">
<li>must hold \(2^{18}\) references to page tables </li>
<li>requires \(2^{18}\times 2^{2}=2^{20}\) or 1MB of space.</li>
</ul>
<p><strong>Key Point</strong>: When the number of entries required in the directory is
so large (in this case 1 MB) that they no longert on a page (in this
case 4 KB) ) add more levels to map larger virtual memories
efficiently.</p>
</div>
</div>

<p>In addition to the formula above:
How many bits do I need to index that table? <code>Bits for page number</code> = log(PTEs per page).</p>
<p>LEVELS. Say we have \(V\) bits to index virtual address.</p>
<p>Then the <code>levels</code> = \(\left\lceil{V- \text{bits for page offset}\over \text{bits for page number}}\right\rceil\). There are different conventions that you can split the page numbers...</p>
<div class='ex'>
<div class="ex-title">
In-Class Problems: Simple Paging
</div>

<div class='ex-content'>
Consider a paging-based virtual memory system with 32-bit virtual and physical addresses, and a page
size of \(2^{12}\) bytes (4KB). Suppose that process \(P\) is running. \(P\) uses only 128KB of virtual memory. The first
5 entries of \(P\)’s page table are shown below.

<pre>
<code>
        ----------------------
Page #  || Frame #  | Valid ||
0x0     || 0x00234  | 1     ||
0x1     || 0x00235  | 1     ||
0x2     || 0x0023f  | 1     ||
0x3     || 0x00ace  | 1     ||
0x4     || 0x00004  | 1     ||
        ----------------------
</code>
</pre>



Answer the following questions:
<p><strong>Q1</strong>: What is total number of entries in \(P\)&#39;s page table？</p>
<p>\(2^{32}/2^{12}=2^{20}\) pages. And we have 1 PTE per page.</p>

<p><strong>Q2</strong>: How many of the entries are valid?</p>
<p>128KB / 4KB = 32 valid</p>

<p><strong>Q3</strong>: Which physical addresses correspond to each of these virtual addresses?</p>
<pre>
<code>
     v             p
0x00001a60 --- 0x235A60<br>0x00000fb5 --- 0x234FB5
0x00004664 --- 0x4664
</code>
</pre>

<p><strong>Q4</strong>: If the page size were 16KB instead of 4KB, how many entries would there be in P’s page table? How
many bits of each virtual address would be used for the offset, and how many for the page number?</p>
<p>\(2^{32}/2^{14} = 2^{18}\) pages. Then repeat the previous steps...</p>
<br>
<p><strong>Side note</strong>:
<ul class="list">
<li># of bits for offset = log(page size) = \(\log(2^{12})=12\). So 3 hex digits for offset.</li>
<li># of PTEs: done in Q1.</li>
<li># of Bits for page number = log(# of PTEs) = 20. So 5 hex digits for page number.</li>
</ul>
</p>
</div>
</div>

<div class='ex'>
<div class="ex-title">
In-Class Problems: Multi-Level Paging
</div>

<div class='ex-content'>
Consider a virtual memory system that uses multi-level paging for address translation. Virtual addresses
and physical addresses are 64 bits long. The page size is 1 MB (\(2^{20}\) bytes). The size of a page table entry is
16 (\(2^4\)) bytes. Each individual page table, at each level, must fit in a single frame.

<p><strong>Q1</strong>: How many bits of each virtual address are needed to represent the page offset?</p>
<p>\(\log(2^{20})=20\) bits</p>

<p><strong>Q2</strong>: What is the maximum number of entries in an individual page table?</p>
<p>\(2^{20}/2^4 = 2^{16}\) entries</p>

<p><strong>Q3</strong>: What is the number of levels of page tables that will be required for virtual-to-physical translation in
this system?</p>
<p>\(\left\lceil{64-20\over 16}\right\rceil = 3\)</p>

<p><strong>Q4</strong>: Suppose that a particular process uses only 128 MB (\(2^{27}\)bytes) of virtual memory, with a virtual
address range from 0 to \(2^{27}-1\). How many individual page tables, at each level, will be required to
translate this process’ address space?</p>
<p>
1 -&gt; 1 -&gt; 1.
</p>

<img src="/pics/multilevelpaging.svg" width=100%>

<p>We only use lower 27 bits here in virtual address...</p>
</div>
</div>

<h1 id="some-good-problems-for-midterm??"><a class="header-link" href="#some-good-problems-for-midterm??"></a>Some good problems for midterm??</h1>
<p><em>Explain the difference between internal and external fragmentation.</em></p>
<p>From <a href="https://courses.cs.washington.edu/courses/cse451/00sp/misc/quiz2sol.txt">CSE451, University of Washington</a>:</p>
<blockquote>
<p>Internal fragmentation is the wasted space within each allocated block
because of rounding up from the actual requested allocation to the
allocation granularity.  External fragmentation is the various free
spaced holes that are generated in either your memory or disk space.
External fragmented blocks are available for allocation, but may be
too small to be of any use.</p>
</blockquote>
<p>So paging eliminates external frag., not internal frag.</p>
<h1 id="after-midterm"><a class="header-link" href="#after-midterm"></a>after midterm</h1>
<blockquote>
<p>Lec 13 44:46</p>
</blockquote>
<!--end-->
</div>
